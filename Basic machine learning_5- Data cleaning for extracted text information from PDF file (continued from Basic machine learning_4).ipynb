{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic machine learning_5- Data cleaning for extracted text information from PDF file (continued from Basic machine learning_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in relevant libraries from python\n",
    "from io import StringIO\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import os\n",
    "import sys, getopt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# creating function to converts PDF file and returns its text content as a string\n",
    "def convert(file_name, pages):\n",
    "    if not pages:\n",
    "        pagenums = set()\n",
    "    else:\n",
    "        pagenums = set(pages)\n",
    "\n",
    "    OUTPUT = StringIO()\n",
    "    MANAGER = PDFResourceManager()\n",
    "    CONVERTER = TextConverter(MANAGER, OUTPUT, laparams=LAParams())\n",
    "    INTERPRETER = PDFPageInterpreter(MANAGER, CONVERTER)\n",
    "\n",
    "    PDF_FILE = open(file_name, 'rb')\n",
    "    for page in PDFPage.get_pages(PDF_FILE, pagenums):\n",
    "        INTERPRETER.process_page(page)\n",
    "    PDF_FILE.close()\n",
    "    CONVERTER.close()\n",
    "    text_parsed = OUTPUT.getvalue()\n",
    "    OUTPUT.close\n",
    "    return text_parsed \n",
    "\n",
    "# Call function \n",
    "extracted_text= convert('dummy_file.pdf', pages=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Raw extracted text--\n",
      "['International Conference on Soft Computing and Machine Learning (SCML2019) ', 'April 26th-29th, 2019, Wuhan, China ', 'Part I Conference Schedule   ', 'Friday, April 26th, 2019   ', 'Time ', 'Activity ', 'Location ', '08:00-18:00  Registration ', 'International Academic Exchange Center in HUST ', '(华中科技大学国际学术交流中心) ', ' ', 'Notes: Please take Participating Card during the conference. ', ' ', ' ', ' ', ' ', ' ', ' ', '2 ']\n",
      "\n",
      "--Cleaned extracted text- Removed whitespaces--\n",
      "['International Conference on Soft Computing and Machine Learning (SCML2019) ', 'April 26th-29th, 2019, Wuhan, China ', 'Part I Conference Schedule   ', 'Friday, April 26th, 2019   ', 'Time ', 'Activity ', 'Location ', '08:00-18:00  Registration ', 'International Academic Exchange Center in HUST ', '(华中科技大学国际学术交流中心) ', 'Notes: Please take Participating Card during the conference. ', '2 ']\n",
      "\n",
      "--Cleaned extracted text- Removed trailing whitespaces--\n",
      "['International Conference on Soft Computing and Machine Learning (SCML2019)', 'April 26th-29th, 2019, Wuhan, China', 'Part I Conference Schedule', 'Friday, April 26th, 2019', 'Time', 'Activity', 'Location', '08:00-18:00  Registration', 'International Academic Exchange Center in HUST', '(华中科技大学国际学术交流中心)', 'Notes: Please take Participating Card during the conference.', '2']\n",
      "\n",
      "--Cleaned extracted text- Removed all digits--\n",
      "['International Conference on Soft Computing and Machine Learning (SCML)', 'April th-th, , Wuhan, China', 'Part I Conference Schedule', 'Friday, April th, ', 'Time', 'Activity', 'Location', ':-:  Registration', 'International Academic Exchange Center in HUST', '(华中科技大学国际学术交流中心)', 'Notes: Please take Participating Card during the conference.', '']\n",
      "\n",
      "--Final cleaned extracted text--\n",
      "['International Conference on Soft Computing and Machine Learning (SCML)', 'April th-th, , Wuhan, China', 'Part I Conference Schedule', 'Friday, April th, ', 'Time', 'Activity', 'Location', ':-:  Registration', 'International Academic Exchange Center in HUST', 'Notes: Please take Participating Card during the conference.']\n"
     ]
    }
   ],
   "source": [
    "# import string library from python\n",
    "import string\n",
    "range_of_alphabets = string.ascii_letters # optional choice (import range of lower- and upper-case letters)\n",
    "range_of_punctuations = string.punctuation # optional choice (import range of punctuation characters)\n",
    "\n",
    "# data cleaning for plant classification\n",
    "extracted_text_list = list() # create empty list to contain cleaned parsed text from PDF file\n",
    "\n",
    "# Step 1: Extract out each sentence (before the next line) and store into empty list\n",
    "dummy_text = ''\n",
    "for item in extracted_text:\n",
    "    if item != '\\n': # check if item is actually a new line\n",
    "        dummy_text += item\n",
    "    else:\n",
    "        if len(dummy_text) > 0:\n",
    "            extracted_text_list.append(dummy_text)\n",
    "        dummy_text = ''        \n",
    "print('--Raw extracted text--')\n",
    "print(extracted_text_list)\n",
    "print('')\n",
    "\n",
    "# Step 2: remove all whitespaces strings from appended list\n",
    "extracted_text_list = [item for item in extracted_text_list if item != ' ']\n",
    "print('--Cleaned extracted text- Removed whitespaces--')\n",
    "print(extracted_text_list)\n",
    "print('')\n",
    "\n",
    "# Step 3: remove all trailing whitespaces from updated appended list of step 2\n",
    "extracted_text_list = [item.strip() for item in extracted_text_list if item != ' ']\n",
    "print('--Cleaned extracted text- Removed trailing whitespaces--')\n",
    "print(extracted_text_list)\n",
    "print('')\n",
    "\n",
    "# Step 3: remove all digits from updated appended list of step 3 (if required)\n",
    "import re\n",
    "extracted_text_list = [re.sub(r'\\d+', '', text) for text in extracted_text_list]\n",
    "print('--Cleaned extracted text- Removed all digits--')\n",
    "print(extracted_text_list)\n",
    "print('')\n",
    "\n",
    "# Step 4: Final check to remove whitespaces or empty strings and strings which contain no alphabets\n",
    "final_list = list()\n",
    "for main_item in extracted_text_list:\n",
    "    count = 0\n",
    "    for sub_item in main_item:\n",
    "        if sub_item in range_of_alphabets:\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        final_list.append(main_item)\n",
    "print('--Final cleaned extracted text--')\n",
    "print(final_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
